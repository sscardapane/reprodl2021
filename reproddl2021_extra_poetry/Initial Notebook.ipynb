{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "41941c58",
   "metadata": {},
   "source": [
    "## Reproducible Deep Learning (PhD course, Data Science)\n",
    "### Lecture 1: deep learning recap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "560e6bc9",
   "metadata": {},
   "source": [
    "We will code a simple audio classification model (a convolutional neural network) for the ESC-50 dataset: https://github.com/karolpiczak/ESC-50. The aim is to recap some deep learning concepts, and have a working notebook to use as starting point for the next exercises."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "101dbfc5",
   "metadata": {},
   "source": [
    "**Setup the machine**:\n",
    "1. Follow the instructions from here: https://github.com/sscardapane/reprodl2021#local-set-up\n",
    "2. Download the ESC-50 dataset inside a 'data' folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01c704b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, torchaudio\n",
    "from torch import nn\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a5e948",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.metrics import functional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f355c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b39379",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95517d77",
   "metadata": {},
   "source": [
    "### Step 1: Some experiments in audio loading and transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5cd717c",
   "metadata": {},
   "source": [
    "The code in this section is just for experimentation, and will be removed when porting to a script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bbb27a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Substitute this with your actual path. This is the root folder of ESC-50, where\n",
    "# you can find the subfolders 'audio' and 'meta'.\n",
    "datapath = Path('data/ESC-50')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b0f312b",
   "metadata": {},
   "outputs": [],
   "source": [
    "datapath.exists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4acc956",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Path is fundamental to have reproducible code across different operating systems.\n",
    "csv = pd.read_csv(datapath / Path('meta/esc50.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "739a8c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need only filename, fold, and target\n",
    "csv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae685bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can use torchaudio.load to load the file. The second value is the sampling rate of the file.\n",
    "x, sr = torchaudio.load(datapath / 'audio' / csv.iloc[0, 0], normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af05f9b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5304dd53",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x[0, ::5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f39705e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful transformation to resample the original file.\n",
    "torchaudio.transforms.Resample(orig_freq=sr, new_freq=8000)(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9556f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Another useful transformation to build a Mel spectrogram (image-like), so that\n",
    "# we can apply any CNN on top of it.\n",
    "h = torchaudio.transforms.MelSpectrogram(sample_rate=sr)(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce2cf845",
   "metadata": {},
   "outputs": [],
   "source": [
    "h.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4dc659b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to DB magnitude, useful for scaling.\n",
    "# Note: values could be further normalize to significantly speed-up and simplify training.\n",
    "h = torchaudio.transforms.AmplitudeToDB()(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de81041e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(h[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9804195b",
   "metadata": {},
   "source": [
    "### Step 2: Putting together data loading and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf5523f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ESC50Dataset(torch.utils.data.Dataset):\n",
    "    # Simple class to load the desired folders inside ESC-50\n",
    "    \n",
    "    def __init__(self, path: Path = Path('data/ESC-50'), \n",
    "                 sample_rate: int = 8000,\n",
    "                 folds = [1]):\n",
    "        # Load CSV & initialize all torchaudio.transforms:\n",
    "        # Resample --> MelSpectrogram --> AmplitudeToDB\n",
    "        self.path = path\n",
    "        self.csv = pd.read_csv(path / Path('meta/esc50.csv'))\n",
    "        self.csv = self.csv[self.csv['fold'].isin(folds)]\n",
    "        self.resample = torchaudio.transforms.Resample(\n",
    "            orig_freq=44100, new_freq=sample_rate\n",
    "        )\n",
    "        self.melspec = torchaudio.transforms.MelSpectrogram(\n",
    "            sample_rate=sample_rate)\n",
    "        self.db = torchaudio.transforms.AmplitudeToDB(top_db=80)\n",
    "        \n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        # Returns (xb, yb) pair, after applying all transformations on the audio file.\n",
    "        row = self.csv.iloc[index]\n",
    "        wav, _ = torchaudio.load(self.path / 'audio' / row['filename'])\n",
    "        label = row['target']\n",
    "        xb = self.db(\n",
    "            self.melspec(\n",
    "                self.resample(wav)\n",
    "            )\n",
    "        )\n",
    "        return xb, label\n",
    "        \n",
    "    def __len__(self):\n",
    "        # Returns length\n",
    "        return len(self.csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22500d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = ESC50Dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "932afe75",
   "metadata": {},
   "outputs": [],
   "source": [
    "for xb, yb in train_data:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e09146bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "xb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c98a885d",
   "metadata": {},
   "outputs": [],
   "source": [
    "yb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce75d8fc",
   "metadata": {},
   "source": [
    "### Step 3: Build a classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea1fb4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use folds 1,2,3 for training, 4 for validation, 5 for testing.\n",
    "train_data = ESC50Dataset(folds=[1,2,3])\n",
    "val_data = ESC50Dataset(folds=[4])\n",
    "test_data = ESC50Dataset(folds=[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66cf2c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = \\\n",
    "    torch.utils.data.DataLoader(train_data, batch_size=8, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51893cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loader = torch.utils.data.DataLoader(val_data, batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ccab6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a21ad399",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AudioNet(pl.LightningModule):\n",
    "    \n",
    "    def __init__(self, n_classes = 50, base_filters = 32):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, base_filters, 11, padding=5)\n",
    "        self.bn1 = nn.BatchNorm2d(base_filters)\n",
    "        self.conv2 = nn.Conv2d(base_filters, base_filters, 3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(base_filters)\n",
    "        self.pool1 = nn.MaxPool2d(2)\n",
    "        self.conv3 = nn.Conv2d(base_filters, base_filters * 2, 3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(base_filters * 2)\n",
    "        self.conv4 = nn.Conv2d(base_filters * 2, base_filters * 4, 3, padding=1)\n",
    "        self.bn4 = nn.BatchNorm2d(base_filters * 4)\n",
    "        self.pool2 = nn.MaxPool2d(2)\n",
    "        self.fc1 = nn.Linear(base_filters * 4, n_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(self.bn1(x))\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(self.bn2(x))\n",
    "        x = self.pool1(x)\n",
    "        x = self.conv3(x)\n",
    "        x = F.relu(self.bn3(x))\n",
    "        x = self.conv4(x)\n",
    "        x = F.relu(self.bn4(x))\n",
    "        x = self.pool2(x)\n",
    "        x = F.adaptive_avg_pool2d(x, (1, 1))\n",
    "        x = self.fc1(x[:, :, 0, 0])\n",
    "        return x\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        # Very simple training loop\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = F.cross_entropy(y_hat, y)\n",
    "        self.log('train_loss', loss, on_step=True)\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        y_hat = torch.argmax(y_hat, dim=1)\n",
    "        acc = functional.accuracy(y_hat, y)\n",
    "        self.log('val_acc', acc, on_epoch=True, prog_bar=True)\n",
    "        return acc\n",
    "        \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39db6dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.seed_everything(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59fcc423",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test that the network works on a single mini-batch\n",
    "audionet = AudioNet()\n",
    "xb, yb = next(iter(train_loader))\n",
    "audionet(xb).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c02e9e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = pl.Trainer(gpus=1, max_epochs=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b96321",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.fit(audionet, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a34f5f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: implement the test loop.\n",
    "trainer.test(audionet, test_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python392jvsc74a57bd00c2957c63632f759fc0cf13e071f3ad17ebc9d4e3ef4ac1c8eb2a54d071c755d",
   "display_name": "Python 3.9.2 64-bit ('reprodl': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}