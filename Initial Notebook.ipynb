{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "41941c58",
   "metadata": {},
   "source": [
    "## Reproducible Deep Learning (PhD course, Data Science)\n",
    "### Lecture 1: deep learning recap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "560e6bc9",
   "metadata": {},
   "source": [
    "We will code a simple audio classification model (a convolutional neural network) for the ESC-50 dataset: https://github.com/karolpiczak/ESC-50. The aim is to recap some deep learning concepts, and have a working notebook to use as starting point for the next exercises."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "101dbfc5",
   "metadata": {},
   "source": [
    "**Setup the machine**:\n",
    "1. Follow the instructions from here: https://github.com/sscardapane/reprodl2021#local-set-up\n",
    "2. Download the ESC-50 dataset inside a 'data' folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "01c704b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, torchaudio\n",
    "from torch import nn\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "76a5e948",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "1f355c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e3b39379",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95517d77",
   "metadata": {},
   "source": [
    "### Step 1: Some experiments in audio loading and transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5cd717c",
   "metadata": {},
   "source": [
    "The code in this section is just for experimentation, and will be removed when porting to a script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0bbb27a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Substitute this with your actual path. This is the root folder of ESC-50, where\n",
    "# you can find the subfolders 'audio' and 'meta'.\n",
    "datapath = Path('data/ESC-50')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8b0f312b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datapath.exists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e4acc956",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Path is fundamental to have reproducible code across different operating systems.\n",
    "csv = pd.read_csv(datapath / Path('meta/esc50.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "739a8c6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>fold</th>\n",
       "      <th>target</th>\n",
       "      <th>category</th>\n",
       "      <th>esc10</th>\n",
       "      <th>src_file</th>\n",
       "      <th>take</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1-100032-A-0.wav</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>dog</td>\n",
       "      <td>True</td>\n",
       "      <td>100032</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1-100038-A-14.wav</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>chirping_birds</td>\n",
       "      <td>False</td>\n",
       "      <td>100038</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1-100210-A-36.wav</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "      <td>vacuum_cleaner</td>\n",
       "      <td>False</td>\n",
       "      <td>100210</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1-100210-B-36.wav</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "      <td>vacuum_cleaner</td>\n",
       "      <td>False</td>\n",
       "      <td>100210</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1-101296-A-19.wav</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>thunderstorm</td>\n",
       "      <td>False</td>\n",
       "      <td>101296</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            filename  fold  target        category  esc10  src_file take\n",
       "0   1-100032-A-0.wav     1       0             dog   True    100032    A\n",
       "1  1-100038-A-14.wav     1      14  chirping_birds  False    100038    A\n",
       "2  1-100210-A-36.wav     1      36  vacuum_cleaner  False    100210    A\n",
       "3  1-100210-B-36.wav     1      36  vacuum_cleaner  False    100210    B\n",
       "4  1-101296-A-19.wav     1      19    thunderstorm  False    101296    A"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We need only filename, fold, and target\n",
    "csv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ae685bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can use torchaudio.load to load the file. The second value is the sampling rate of the file.\n",
    "x, sr = torchaudio.load(datapath / 'audio' / csv.iloc[0, 0], normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "af05f9b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 220500])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5304dd53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1c349971220>]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(x[0, ::5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f39705e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 40000])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Useful transformation to resample the original file.\n",
    "torchaudio.transforms.Resample(orig_freq=sr, new_freq=8000)(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e9556f4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\simon\\anaconda3\\envs\\reprodl\\lib\\site-packages\\torchaudio\\functional\\functional.py:357: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (128) may be set too high. Or, the value for `n_freqs` (201) may be set too low.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Another useful transformation to build a Mel spectrogram (image-like), so that\n",
    "# we can apply any CNN on top of it.\n",
    "h = torchaudio.transforms.MelSpectrogram(sample_rate=sr)(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ce2cf845",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 128, 1103])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f4dc659b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to DB magnitude, useful for scaling.\n",
    "# Note: values could be further normalize to significantly speed-up and simplify training.\n",
    "h = torchaudio.transforms.AmplitudeToDB()(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "de81041e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1c3483fc850>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(h[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9804195b",
   "metadata": {},
   "source": [
    "### Step 2: Putting together data loading and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "cf5523f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ESC50Dataset(torch.utils.data.Dataset):\n",
    "    # Simple class to load the desired folders inside ESC-50\n",
    "    \n",
    "    def __init__(self, path: Path = Path('data/ESC-50'), \n",
    "                 sample_rate: int = 8000,\n",
    "                 folds = [1]):\n",
    "        # Load CSV & initialize all torchaudio.transforms:\n",
    "        # Resample --> MelSpectrogram --> AmplitudeToDB\n",
    "        self.path = path\n",
    "        self.csv = pd.read_csv(path / Path('meta/esc50.csv'))\n",
    "        self.csv = self.csv[self.csv['fold'].isin(folds)]\n",
    "        self.resample = torchaudio.transforms.Resample(\n",
    "            orig_freq=44100, new_freq=sample_rate\n",
    "        )\n",
    "        self.melspec = torchaudio.transforms.MelSpectrogram(\n",
    "            sample_rate=sample_rate)\n",
    "        self.db = torchaudio.transforms.AmplitudeToDB(top_db=80)\n",
    "        \n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        # Returns (xb, yb) pair, after applying all transformations on the audio file.\n",
    "        row = self.csv.iloc[index]\n",
    "        wav, _ = torchaudio.load(self.path / 'audio' / row['filename'])\n",
    "        label = row['target']\n",
    "        xb = self.db(\n",
    "            self.melspec(\n",
    "                self.resample(wav)\n",
    "            )\n",
    "        )\n",
    "        return xb, label\n",
    "        \n",
    "    def __len__(self):\n",
    "        # Returns length\n",
    "        return len(self.csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "22500d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = ESC50Dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "932afe75",
   "metadata": {},
   "outputs": [],
   "source": [
    "for xb, yb in train_data:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "e09146bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 128, 201])"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "c98a885d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce75d8fc",
   "metadata": {},
   "source": [
    "### Step 3: Build a classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "2ea1fb4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use folds 1,2,3 for training, 4 for validation, 5 for testing.\n",
    "train_data = ESC50Dataset(folds=[1,2,3])\n",
    "val_data = ESC50Dataset(folds=[4])\n",
    "test_data = ESC50Dataset(folds=[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "66cf2c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = \\\n",
    "    torch.utils.data.DataLoader(train_data, batch_size=8, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "51893cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loader = torch.utils.data.DataLoader(val_data, batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "f3ccab6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "a21ad399",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AudioNet(pl.LightningModule):\n",
    "    \n",
    "    def __init__(self, n_classes = 50, base_filters = 32):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, base_filters, 11, padding=5)\n",
    "        self.bn1 = nn.BatchNorm2d(base_filters)\n",
    "        self.conv2 = nn.Conv2d(base_filters, base_filters, 3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(base_filters)\n",
    "        self.pool1 = nn.MaxPool2d(2)\n",
    "        self.conv3 = nn.Conv2d(base_filters, base_filters * 2, 3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(base_filters * 2)\n",
    "        self.conv4 = nn.Conv2d(base_filters * 2, base_filters * 4, 3, padding=1)\n",
    "        self.bn4 = nn.BatchNorm2d(base_filters * 4)\n",
    "        self.pool2 = nn.MaxPool2d(2)\n",
    "        self.fc1 = nn.Linear(base_filters * 4, n_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(self.bn1(x))\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(self.bn2(x))\n",
    "        x = self.pool1(x)\n",
    "        x = self.conv3(x)\n",
    "        x = F.relu(self.bn3(x))\n",
    "        x = self.conv4(x)\n",
    "        x = F.relu(self.bn4(x))\n",
    "        x = self.pool2(x)\n",
    "        x = F.adaptive_avg_pool2d(x, (1, 1))\n",
    "        x = self.fc1(x[:, :, 0, 0])\n",
    "        return x\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        # Very simple training loop\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = F.cross_entropy(y_hat, y)\n",
    "        self.log('train_loss', loss, on_step=True)\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        y_hat = torch.argmax(y_hat, dim=1)\n",
    "        acc = pl.metrics.functional.accuracy(y_hat, y)\n",
    "        self.log('val_acc', acc, on_epoch=True, prog_bar=True)\n",
    "        return acc\n",
    "        \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "39db6dfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl.seed_everything(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "59fcc423",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 50])"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test that the network works on a single mini-batch\n",
    "audionet = AudioNet()\n",
    "xb, yb = next(iter(train_loader))\n",
    "audionet(xb).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "c02e9e07",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(gpus=1, max_epochs=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "f4b96321",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name  | Type        | Params\n",
      "---------------------------------------\n",
      "0  | conv1 | Conv2d      | 3.9 K \n",
      "1  | bn1   | BatchNorm2d | 64    \n",
      "2  | conv2 | Conv2d      | 9.2 K \n",
      "3  | bn2   | BatchNorm2d | 64    \n",
      "4  | pool1 | MaxPool2d   | 0     \n",
      "5  | conv3 | Conv2d      | 18.5 K\n",
      "6  | bn3   | BatchNorm2d | 128   \n",
      "7  | conv4 | Conv2d      | 73.9 K\n",
      "8  | bn4   | BatchNorm2d | 256   \n",
      "9  | pool2 | MaxPool2d   | 0     \n",
      "10 | fc1   | Linear      | 6.5 K \n",
      "---------------------------------------\n",
      "112 K     Trainable params\n",
      "0         Non-trainable params\n",
      "112 K     Total params\n",
      "0.450     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87fdbf1bf63d482f9088c64770977752",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\simon\\anaconda3\\envs\\reprodl\\lib\\site-packages\\pytorch_lightning\\utilities\\distributed.py:68: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.fit(audionet, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "a34f5f78",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\simon\\anaconda3\\envs\\reprodl\\lib\\site-packages\\pytorch_lightning\\utilities\\distributed.py:68: UserWarning: you passed in a test_dataloader but have no test_step. Skipping test loop\n",
      "  warnings.warn(*args, **kwargs)\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: implement the test loop.\n",
    "trainer.test(audionet, test_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
